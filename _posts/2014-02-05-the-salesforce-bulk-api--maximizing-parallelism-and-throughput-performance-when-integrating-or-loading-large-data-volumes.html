---
layout: post
title: 'The Salesforce Bulk API – Maximizing Parallelism and Throughput Performance When Integrating or Loading Large Data Volumes'
url: https://developer.salesforce.com/blogs/engineering/2014/02/the-salesforce-bulk-api-maximizing-parallelism-and-throughput-performance-when-integrating-or-loading-large-data-volumes.html
source: https://developer.salesforce.com/blogs/engineering/2014/02/the-salesforce-bulk-api-maximizing-parallelism-and-throughput-performance-when-integrating-or-loading-large-data-volumes.html
domain: developer.salesforce.com
image: http://kinlane-productions.s3.amazonaws.com/screen-capture-api/developer-salesforce-comblogsengineering201402the-salesforce-bulk-api-maximizing-parallelism-and-throughput-performance-when-integrating-or-loading-large-data-volumes-html.png
---

<p>Data loads and integrations that perform poorly or fail altogether are among the most significant problems during salesforce.com customers’ “go-live” efforts.They can both put timelines at risk and become unimaginably expensive, especially for enterprise-scale organizations.If you’re a Salesforce architect or developer, you can save your organization both time and money—and get up to 20 million records into your organization per hour—when you properly plan and execute your large loads and integrations using the Bulk API. On the surface, one of the most important loading and integration best practices is simple: When you run a Bulk API job, processing more of its batches in parallel means giving that job a higher degree of parallelism, which in turn gives your run better throughput.</p>
